{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import load_model  \n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 50000\n",
    "x_train = x_train[start_index:start_index + 10000]\n",
    "y_train = y_train[start_index:start_index + 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_target = load_model('model\\\\model_target.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 29s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model_target.predict(x_train,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 35s 3ms/step\n",
      "Test loss: 0.0692785954458057\n",
      "Test accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "score = model_target.evaluate(x_train, y_train, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5174186e-12 3.4132281e-08 8.4566388e-08 ... 4.8526605e-10\n",
      "  2.5896250e-07 2.8009413e-09]\n",
      " [1.4489739e-10 3.0214679e-08 2.8402707e-07 ... 2.0214571e-08\n",
      "  9.9999964e-01 3.7746690e-09]\n",
      " [7.9236048e-07 2.8518596e-10 2.0478176e-08 ... 1.4144844e-10\n",
      "  1.8235937e-09 1.3258870e-09]\n",
      " ...\n",
      " [3.5377172e-09 1.1296219e-11 1.8951390e-13 ... 6.4691789e-12\n",
      "  5.2360147e-06 6.4371750e-07]\n",
      " [2.5302222e-06 8.6893021e-10 2.9372609e-07 ... 3.6117262e-10\n",
      "  1.9154623e-08 7.7657987e-09]\n",
      " [3.1944333e-07 3.9047893e-11 1.0002770e-07 ... 1.2479190e-08\n",
      "  9.9999630e-01 3.1621516e-06]]\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(prediction)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape = (784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.4034 - acc: 0.8726\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 10s 976us/step - loss: 0.1699 - acc: 0.9485\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 10s 988us/step - loss: 0.1168 - acc: 0.9680\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0956 - acc: 0.9744\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 10s 994us/step - loss: 0.0828 - acc: 0.9815\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 10s 969us/step - loss: 0.0771 - acc: 0.9826\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 10s 966us/step - loss: 0.0723 - acc: 0.9847\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0643 - acc: 0.9871\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0671 - acc: 0.9859\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0628 - acc: 0.9886\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0616 - acc: 0.9890\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 10s 994us/step - loss: 0.0596 - acc: 0.9875\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.0575 - acc: 0.9898\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0593 - acc: 0.9884\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 9s 935us/step - loss: 0.0581 - acc: 0.9883\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 10s 968us/step - loss: 0.0559 - acc: 0.9907\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 10s 973us/step - loss: 0.0559 - acc: 0.9898\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 9s 929us/step - loss: 0.0534 - acc: 0.9907\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 10s 989us/step - loss: 0.0554 - acc: 0.98991s - loss: 0.0556 - a\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 10s 952us/step - loss: 0.0542 - acc: 0.9907\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 9s 895us/step - loss: 0.0559 - acc: 0.9893 0s - loss: 0.0546 - acc: 0.\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 9s 917us/step - loss: 0.0528 - acc: 0.9916\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 9s 867us/step - loss: 0.0525 - acc: 0.9897\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 10s 957us/step - loss: 0.0512 - acc: 0.9911\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 9s 910us/step - loss: 0.0520 - acc: 0.9917\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0509 - acc: 0.9903\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 9s 932us/step - loss: 0.0507 - acc: 0.9918\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 10s 952us/step - loss: 0.0506 - acc: 0.9920\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 9s 878us/step - loss: 0.0501 - acc: 0.9916\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 10s 958us/step - loss: 0.0504 - acc: 0.9900\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 9s 893us/step - loss: 0.0492 - acc: 0.9909\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 9s 925us/step - loss: 0.0490 - acc: 0.9926\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 9s 935us/step - loss: 0.0503 - acc: 0.9907\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 9s 900us/step - loss: 0.0489 - acc: 0.9919\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 9s 937us/step - loss: 0.0495 - acc: 0.9922\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 10s 967us/step - loss: 0.0488 - acc: 0.9927\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 10s 976us/step - loss: 0.0491 - acc: 0.99201s - loss: 0.0488 - \n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.0491 - acc: 0.9917\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0478 - acc: 0.9926\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0491 - acc: 0.9921\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 9s 915us/step - loss: 0.0470 - acc: 0.9926\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 9s 943us/step - loss: 0.0484 - acc: 0.9920 1s - loss: 0.0482\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 9s 875us/step - loss: 0.0468 - acc: 0.9922\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 9s 909us/step - loss: 0.0489 - acc: 0.9921\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 9s 922us/step - loss: 0.0481 - acc: 0.9923\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 9s 864us/step - loss: 0.0467 - acc: 0.9917\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 9s 905us/step - loss: 0.0470 - acc: 0.9912\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 9s 896us/step - loss: 0.0468 - acc: 0.9927 3s - loss: 0.0486  - ETA: 2s - loss: 0.0481\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 10s 975us/step - loss: 0.0471 - acc: 0.99302s - loss: 0.0\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0469 - acc: 0.9915\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0467 - acc: 0.9935\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0454 - acc: 0.9942\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.0467 - acc: 0.9920\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 9s 912us/step - loss: 0.0458 - acc: 0.9928\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 10s 957us/step - loss: 0.0463 - acc: 0.99281s - loss: 0.0456  - ETA: 0s - loss: 0.0464 - acc: 0.9\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 9s 932us/step - loss: 0.0459 - acc: 0.9918\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 10s 968us/step - loss: 0.0453 - acc: 0.9934\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 9s 940us/step - loss: 0.0466 - acc: 0.9924\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 9s 935us/step - loss: 0.0454 - acc: 0.9929\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 9s 941us/step - loss: 0.0449 - acc: 0.9930\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 9s 947us/step - loss: 0.0458 - acc: 0.9927\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 9s 878us/step - loss: 0.0455 - acc: 0.9925\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 9s 918us/step - loss: 0.0460 - acc: 0.9935\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 9s 945us/step - loss: 0.0452 - acc: 0.9925\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 10s 994us/step - loss: 0.0455 - acc: 0.9930\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 10s 955us/step - loss: 0.0451 - acc: 0.9930\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 9s 949us/step - loss: 0.0460 - acc: 0.9939\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 9s 931us/step - loss: 0.0446 - acc: 0.9936\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 9s 943us/step - loss: 0.0446 - acc: 0.9931\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 10s 958us/step - loss: 0.0450 - acc: 0.9930\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 10s 965us/step - loss: 0.0439 - acc: 0.9941\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 10s 976us/step - loss: 0.0449 - acc: 0.99275s - loss: - ETA: 2s - loss: 0\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 10s 959us/step - loss: 0.0450 - acc: 0.9944\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 9s 909us/step - loss: 0.0449 - acc: 0.9941\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 9s 922us/step - loss: 0.0444 - acc: 0.9930\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 9s 915us/step - loss: 0.0442 - acc: 0.9939\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 9s 949us/step - loss: 0.0446 - acc: 0.9946\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 952us/step - loss: 0.0438 - acc: 0.99299s \n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 9s 933us/step - loss: 0.0437 - acc: 0.9937\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 9s 913us/step - loss: 0.0443 - acc: 0.9944\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 10s 986us/step - loss: 0.0437 - acc: 0.9946\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 9s 931us/step - loss: 0.0443 - acc: 0.9930\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 9s 903us/step - loss: 0.0441 - acc: 0.9933 1s - loss: 0.0458 - a\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 9s 945us/step - loss: 0.0438 - acc: 0.9941\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 9s 917us/step - loss: 0.0430 - acc: 0.9946 2s - loss\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 9s 937us/step - loss: 0.0454 - acc: 0.9933\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 9s 888us/step - loss: 0.0436 - acc: 0.9935\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 9s 927us/step - loss: 0.0444 - acc: 0.9928\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 7s 749us/step - loss: 0.0435 - acc: 0.9942\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 8s 766us/step - loss: 0.0436 - acc: 0.9941\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 7s 735us/step - loss: 0.0437 - acc: 0.9929\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 7s 713us/step - loss: 0.0432 - acc: 0.9947\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 6s 588us/step - loss: 0.0439 - acc: 0.9939\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 6s 626us/step - loss: 0.0430 - acc: 0.9941 0s - loss: 0.0437 - acc: 0.\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 5s 481us/step - loss: 0.0436 - acc: 0.9948\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.0432 - acc: 0.9936\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.0430 - acc: 0.9937\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 3s 339us/step - loss: 0.0434 - acc: 0.9941\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 2s 241us/step - loss: 0.0432 - acc: 0.9942\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 2s 224us/step - loss: 0.0428 - acc: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14b232ad0b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,prediction,\n",
    "                    batch_size = 64,\n",
    "                    epochs = 100,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model\\\\shadow5_T_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 95us/step\n",
      "Test loss: 0.11949695951246832\n",
      "Test accuracy: 0.9683\n"
     ]
    }
   ],
   "source": [
    "x_test = x_test.reshape(10000,784)\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
